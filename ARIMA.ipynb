{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Imports First"
      ],
      "metadata": {
        "id": "dBvv3tArwW1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pandas matplotlib numpy statsmodels scipy seaborn\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.tsa.stattools import acf, pacf\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.forecasting.theta import ThetaModel\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8')"
      ],
      "metadata": {
        "id": "TZu-9Zx6TJqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Dataset"
      ],
      "metadata": {
        "id": "YbRaZlGyTLUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "dates = pd.date_range('1900-01-01', periods=1090, freq='W')\n",
        "# Create seasonal pattern with trend and noise\n",
        "seasonal_pattern = 10 * np.sin(2 * np.pi * np.arange(1090) / 52)\n",
        "trend = 0.01 * np.arange(1090)\n",
        "noise = np.random.normal(0, 2, 1090)\n",
        "temp_values = 15 + seasonal_pattern + trend + noise\n",
        "\n",
        "temp_df = pd.DataFrame({\n",
        "    'date': dates,\n",
        "    'temp': temp_values\n",
        "})\n",
        "temp_df.set_index('date', inplace=True)\n",
        "\n",
        "# Clean the data by removing outliers beyond 3 standard deviations\n",
        "def clean_outliers(series, threshold=3):\n",
        "    mean = series.mean()\n",
        "    std = series.std()\n",
        "    outliers = (series - mean).abs() > threshold * std\n",
        "    cleaned = series.copy()\n",
        "    cleaned[outliers] = np.nan\n",
        "    # Forward fill missing values\n",
        "    cleaned = cleaned.fillna(method='ffill').fillna(method='bfill')\n",
        "    return cleaned\n",
        "\n",
        "temp_df['temp'] = clean_outliers(temp_df['temp'])"
      ],
      "metadata": {
        "id": "NmO_fL9ITOAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It may be useful to eliminate some variability. Let’s create some moving averages in order to smooth it out and plot them to see how they look."
      ],
      "metadata": {
        "id": "dnyOAj5uUs4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create moving averages to smooth the data\n",
        "def moving_average(series, window):\n",
        "    return series.rolling(window=window, center=True).mean()\n",
        "\n",
        "ma7 = moving_average(temp_df, 7)   # Weekly moving average\n",
        "ma30 = moving_average(temp_df, 30)  # Monthly moving average\n",
        "\n",
        "# Plot original data with moving averages\n",
        "plt.figure(figsize=(14, 8))\n",
        "plt.plot(temp_df.index, temp_df, label='Temperature', alpha=0.7, linewidth=1)\n",
        "plt.plot(temp_df.index, ma7, label='MA7 (Weekly)', linewidth=2)\n",
        "plt.plot(temp_df.index, ma30, label='MA30 (Monthly)', linewidth=2)\n",
        "plt.title('Temperature Data with Moving Averages')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Temperature')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "I_VgKZquT-rZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MA30 is too smooth but MA7 works nicely.\n",
        "\n",
        "Now, we take seasonality, trend, and cycle into account with functions from forecast. Essentially, we are finding all the sources of variance from our observations. You can actually see quite a lot just from this too."
      ],
      "metadata": {
        "id": "Li9RiAgQUxpr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# safeguarding for blanks\n",
        "ma7 = ma7.dropna()\n",
        "\n",
        "# Perform seasonal decomposition. For weekly data, we assume 52 weeks per year\n",
        "decomposition = seasonal_decompose(ma7, model='additive', period=52)\n",
        "\n",
        "# Plot decomposition\n",
        "fig, axes = plt.subplots(4, 1, figsize=(14, 12))\n",
        "decomposition.observed.plot(ax=axes[0], title='Original Data (MA7)')\n",
        "decomposition.trend.plot(ax=axes[1], title='Trend')\n",
        "decomposition.seasonal.plot(ax=axes[2], title='Seasonal')\n",
        "decomposition.resid.plot(ax=axes[3], title='Residual')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Remove seasonal component\n",
        "deseasonal_data = ma7['temp']-decomposition.seasonal.values\n",
        "\n",
        "print(\"\\nDecomposition components:\")\n",
        "print(\"- Original: The weekly moving average data\")\n",
        "print(\"- Trend: Long-term movement in the data\")\n",
        "print(\"- Seasonal: Repeating seasonal patterns (52-week cycle)\")\n",
        "print(\"- Residual: Remaining variation after removing trend and seasonality\")"
      ],
      "metadata": {
        "id": "F4iEt1yEVbDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding a good ARIMA Model\n",
        "\n",
        "Remember a model is defined as ARIMA(p, d, q) where:\n",
        "*   p\t=\thow many past observations are considered to affect the current observation (using PCAF, last lag spike)\n",
        "*   d\t=\tdegree of differencing involved (using ADF then differencing [1  3  5 becomes 2  2, which is a single degree of differencing])\n",
        "*   q\t=\torder of the moving average part (ACF, last lag spike).\n",
        "\n"
      ],
      "metadata": {
        "id": "XipZaN87V0DI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for stationarity using Augmented Dickey-Fuller test\n",
        "def check_stationarity(timeseries):\n",
        "    # Perform ADF test\n",
        "    result = adfuller(timeseries.dropna())\n",
        "    return result[1] <= 0.05  # Returns true if stationary\n",
        "\n",
        "diff_value = 0  # this is the \"d\" value\n",
        "is_stationary = check_stationarity(deseasonal_data)\n",
        "deseasonal_diff = deseasonal_data.copy()\n",
        "\n",
        "while not is_stationary:\n",
        "    # If not stationary, apply differencing\n",
        "    if not is_stationary and diff_value <= 3:\n",
        "        deseasonal_diff = deseasonal_diff.diff().dropna()\n",
        "        diff_value += 1\n",
        "        is_stationary = check_stationarity(deseasonal_diff)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "# Plot ACF and PACF to determine p and q parameters\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))\n",
        "\n",
        "# ACF plot\n",
        "plot_acf(deseasonal_diff.dropna(), ax=ax1, lags=40, title='Autocorrelation Function (ACF)')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# PACF plot\n",
        "plot_pacf(deseasonal_diff.dropna(), ax=ax2, lags=40, title='Partial Autocorrelation Function (PACF)')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calculate ACF and PACF values and use them to find significant lags where values exceed approximate 95% confidence bounds\n",
        "acf_values = acf(deseasonal_diff.dropna(), nlags=40)\n",
        "pacf_values = pacf(deseasonal_diff.dropna(), nlags=40)\n",
        "n = len(deseasonal_diff.dropna())\n",
        "confidence_bound = 1.96 / np.sqrt(n) # Rule of thumb, this works to give 95% confidence because maths.\n",
        "significant_acf_lags = []\n",
        "significant_pacf_lags = []\n",
        "\n",
        "for i in range(1, len(acf_values)):\n",
        "    if abs(acf_values[i]) > confidence_bound:\n",
        "        significant_acf_lags.append(i)  # last one will be \"q\" value\n",
        "\n",
        "for i in range(1, len(pacf_values)):\n",
        "    if abs(pacf_values[i]) > confidence_bound:\n",
        "        significant_pacf_lags.append(i)  # last one will be \"p\" value\n",
        "\n",
        "print(f\"\\np={significant_pacf_lags[len(significant_pacf_lags)-1]}\")\n",
        "print(f\"\\nd={diff_value}\")\n",
        "print(f\"\\nd={significant_acf_lags[len(significant_acf_lags)-1]}\")"
      ],
      "metadata": {
        "id": "Yc00m8CQaGoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now fit our ARIMA Model, and we can check its accuracy by holding some data back and showing prediction vs actual.\n",
        "\n",
        "Fitting a model takes a WHILE."
      ],
      "metadata": {
        "id": "bUKIkglwhxrd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Holdout\n",
        "holdout_size = 100\n",
        "train_data = deseasonal_diff.dropna()[:-holdout_size]\n",
        "test_data = deseasonal_diff.dropna()[-holdout_size:]\n",
        "\n",
        "# Fit manual ARIMA model on the training data\n",
        "p_manual = significant_pacf_lags[len(significant_pacf_lags)-1]\n",
        "q_manual = significant_acf_lags[len(significant_acf_lags)-1]\n",
        "arima_model = ARIMA(train_data, order=(p_manual, diff_value, q_manual))\n",
        "arima_fit = arima_model.fit()\n",
        "\n",
        "# Forecast from fitted model\n",
        "forecast_res = arima_fit.get_forecast(steps=holdout_size)\n",
        "forecast = forecast_res.predicted_mean\n",
        "conf_int = forecast_res.conf_int()\n"
      ],
      "metadata": {
        "id": "xd2y2W-ewftw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Common x-ranges\n",
        "train_end = len(train_data)\n",
        "test_range = range(train_end, train_end + holdout_size)\n",
        "\n",
        "# --- 1. Full series plot ---\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(range(len(train_data)), train_data, label='Training Data', alpha=0.7)\n",
        "plt.plot(test_range, test_data, label='Actual (Test)', color='red', linewidth=2)\n",
        "plt.plot(test_range, forecast, label='Forecast', color='blue', linewidth=2, linestyle='--')\n",
        "plt.fill_between(test_range, conf_int.iloc[:, 0], conf_int.iloc[:, 1],\n",
        "                 color='blue', alpha=0.2, label='95% CI')\n",
        "plt.title(f'ARIMA({p_manual},{diff_value},{q_manual}) Forecast – Full Series')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# --- 2. Zoomed-in plot (train_end - 50 to end of holdout) ---\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(range(len(train_data)), train_data, label='Training Data', alpha=0.7)\n",
        "plt.plot(test_range, test_data, label='Actual (Test)', color='red', linewidth=2)\n",
        "plt.plot(test_range, forecast, label='Forecast', color='blue', linewidth=2, linestyle='--')\n",
        "plt.fill_between(test_range, conf_int.iloc[:, 0], conf_int.iloc[:, 1],\n",
        "                 color='blue', alpha=0.2, label='95% CI')\n",
        "plt.xlim(train_end - 50, train_end + holdout_size)\n",
        "plt.title(f'ARIMA({p_manual},{diff_value},{q_manual}) Forecast – Zoomed')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# --- 3. Focused on 970–1000 ---\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(range(len(train_data)), train_data, label='Training Data', alpha=0.7)\n",
        "plt.plot(test_range, test_data, label='Actual (Test)', color='red', linewidth=2)\n",
        "plt.plot(test_range, forecast, label='Forecast', color='blue', linewidth=2, linestyle='--')\n",
        "plt.fill_between(test_range, conf_int.iloc[:, 0], conf_int.iloc[:, 1],\n",
        "                 color='blue', alpha=0.2, label='95% CI')\n",
        "plt.xlim(970, 1000)\n",
        "plt.title(f'ARIMA({p_manual},{diff_value},{q_manual}) Forecast – Range 970–1000')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eKh8YloDoNzK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}